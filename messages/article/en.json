{
  "Article1": {
    "heading": "University-Enterprise Collaboration to Build Artificial Intelligence Innovation Institute",
    "p1": "Huazhong University of Science and Technology and Wuhan Shannon Technology Co.,Ltd. recently signed a cooperation agreement to build Artificial Intelligence Innovation Institute (AIII), which will combine the advantages of R&D, industry, talents and innovation resources to expand the application of artificial intelligence technology in industrial manufacturing, digital content, distributed storage, firefighting, medical, pan-entertainment and other fields. The two companies will combine their strengths in R&D, industry, talents and innovation resources to expand the application of AI technology in industrial manufacturing, digital content, distributed storage, firefighting, medical care, and pan-entertainment.",
    "p2": "The Wuhan Artificial Intelligence Innovation Center of Shannon is an industry-academia-research complex based on the School of HUST, which is mainly engaged in technology research and development, system development, intelligent upgrading and test verification in AI-related fields, promoting the transformation of innovative achievements and industrial incubation, attracting and training first-class scientific research talents, promoting scientific and technological synergy and industrial integration. innovation and industrial integration development, and is committed to becoming a high-level new research institution",
    "p3": "It is reported that, relying on Wuhan's AI industry support policy and the location advantage of high-end industry gathering, the two sides will jointly build a new highland of Wuhan AI industry, and help promote the transformation of scientific and technological achievements and high-level talent training.",
    "p4": "At present, the Innovation Center has gathered a large number of elites and scholars in the field of artificial intelligence, with a core team of 10 scientists, all of whom have PhDs and long-term visiting research experience in well-known foreign AI laboratories. The Center has also invited a number of foreign scientists, including two Nobel Prize winners and one IEEE Fellow, as advisors. There is also a large team of Ph.D. and M.S. students involved in scientific research and technology development.",
    "p5": "The establishment of the AI Innovation Center will accelerate the gathering of talents in Wuhan's new science and technology industries, promote regional digital development and industrial upgrading, enhance the comprehensive strength of Wuhan's science and technology self-research and innovation, and promote the evolution of Wuhan's research in artificial intelligence to a more cutting-edge stage."
  },
  "Article3": {
    "heading": "Novel tagging intelligent labeling system",
    "p1": "According to the 48th \"China Internet Development Statistics Report\" released by China Internet Network Information Center, as of September 2020, the scale of China's online literature users reached 467 million, and the scale of cell phone online literature users reached 465 million. Although affected by the slow demographic dividend of the domestic Internet, the growth rate of online literature users has slowed down compared with the average value of the previous years, but from the data performance of the industry user scale still shows a stable growth of healthy development. The huge scale of users provides a traffic base for the development of online literature, and the strong support and investment of major online literature platforms have led to a spurt of growth in the number of online literature works in recent years. As mentioned in the \"China Internet Literature Copyright Protection Research Report\" released by Ari Consulting in June 2020, the ReadWrite Group has as many as 8.1 million writers in residence as of 2019, with the total number of platform works reaching 12.2 million and 11.5 million of its own original literary works, and new works are constantly emerging.",
    "p2": "The large base and rapid updates of online literature works have brought some troubles and challenges for both authors and readers. For authors of online literature, mastering the current flow direction and the types of works readers are interested in can better guide the direction of writing and increase the number of clicks on their works. For readers, how to choose the works they are interested in is a problem that needs to be solved. Many readers often can only choose from the popular works on the platform, which makes it more and more difficult for some new and excellent works to get clicks, which is not conducive to the long-term development of the whole industry. At the same time, online literary works usually have many words and mixed characters, so it is difficult for readers to sort out the article and the relationship between characters, and they often read and forget, which leads to the limited dissemination of works. In order to provide authors with writing guidance and facilitate readers' selection, work classification is a common solution. By classifying works based on several different dimensions, it facilitates later analysis and visual display, and brings convenience for authors and readers to understand the works. In addition, extracting story highlights from works through text summaries can help readers understand the general plot of a story in advance. In addition to the simple classification of works, in order to help readers sort out the story line and the relationship between characters, all characters appearing in the author can be extracted for character portraits from multiple dimensions and character descriptions and characteristics. In addition, visual display through character relationship mapping is more helpful to understand the intricate relationships among many characters.",
    "p3": "The traditional text analysis method is based on features, i.e., extracting relevant features such as word frequency, lexicality, TF-IDF, etc., and then using Support Vector Machine (SVM) or Gradient Boosted Decision Tree (GBDT), GBDT) machine learning methods for classification. Since 2012, with the rapid development of deep learning technology and GPU performance, natural language processing technology based on deep learning has gradually replaced the traditional manual feature plus machine learning methods. Deep learning-based methods usually do not require artificial features, but map each word into a dense embedding representation, and then go through a designed multilayer neural network, calculate the loss function and update the parameters of the neural network and the embedding representation by the back-propagation algorithm.",
    "header-main-1": "Algorithms Introduction",
    "header-sub-1": "Word2Vec model",
    "p4": "Word2Vec is a method for efficiently obtaining word representations in vector space. word2Vec is based on the intuitive assumption that the semantics of two different words with similar contexts are close. The core idea is to consider that the semantics of a word is influenced by its contextual environment, so the association between the context and the word can be constructed by a neural network with a single hidden layer, so that the parameters of the hidden layer can be used as the representations of the corresponding index words by training such a neural network with a large unlabeled corpus. Word2Vec proposes two training methods for the network, namely CBOW and Skip-Gram, and their model structures are shown in Figure 3-1.",
    "p5": "The core idea of the CBOW model is to predict the word using the peripheral words of the central word by defining a sliding window of fixed length to obtain the central word and the peripheral words, where the peripheral words contain both the above word and the below word. The peripheral word is used as the output of the input layer, the average of the peripheral word embedding vector is used as the output of the hidden layer, and finally the score and cross-entropy loss of the output layer are calculated for back propagation.",
    "p6": "<p>As shown in Equation (3-1), denotes the number of words in context, C denotes the number of words corresponding to words in context, <strong><i>X<sub>1</sub>,...,X<sub>C</sub></i></strong>&nbsp;&nbsp;denotes the unique thermal code corresponding to the word in the context, then <strong><i>V<sub>w1</sub></i></strong> denotes the embedding vector of the word <strong><i>W<sub>1</sub></i></strong>, and the objective function is defined as Equation (3-2).The meaning of this objective function is based on the given context words <strong><i>W<sub>1</sub>,...,W<sub>C</sub></i></strong> Maximize the probability that the output is <strong><i>W<sub>0</sub></i></strong> of the central word: </p>",
    "p7": "<p>The idea of Skip-Gram model is exactly the opposite of CBOW, where the central word is represented as input as <strong><i>W<sub>1</sub></i></strong>, and the context words <strong><i>W<sub>1</sub>,...,W<sub>C</sub></i></strong> as the target output of the prediction. In this case, the objective function is shown in Equation (3-3).</p>",
    "p8": "Both the CBOW model and the Skip-Gram model are based on a large unlabeled corpus and are trained using a backpropagation algorithm. The back-propagation is used to continuously update the hidden layer parameters to ensure that the corresponding representational vectors of words are biased towards their most commonly used semantics.",
    "header-main-2": "Distance vector",
    "p9": "<p>Euclidean distance is the distance between two points in Euclidean space. Euclidean distance is the basic metric distance, which is often used to measure the distance between two vectors. For two vectors <strong><i>X = (x<sub>1</sub>,x<sub>2</sub>,...x<sub>n</sub>)</i></strong> and <strong><i>Y = (y<sub>1</sub>,y<sub>2</sub>,...y<sub>n</sub>)</i></strong>, In this system that corresponds to two text embedded vectors, their Euclidean distance is shown in equation (3-4)</p>",
    "p10": "The cosine distance measures the distance between two vectors by measuring the cosine of their angles, which is also called the cosine similarity and is often used for measuring text similarity. For two text-embedded vectors, their cosine distances are given in equation (3-5).",
    "header-main-3": "Text classifier",
    "p11": "The RNN model structure is shown in Figure 3-2.",
    "caption": "图 3‑2  RNN模型结构图",
    "p12": "<p>According to Figure 3-2 above, The word embedding of the text sequence is represented as <strong><i>x<sub>0</sub>,x<sub>1</sub>,x<sub>2</sub>,...,x<sub>t</sub></i></strong>，input <strong><i>t</i></strong> at the time <strong><i>x<sub>t</sub></i></strong> and the output state <strong><i>h<sub>t-1</sub></i></strong> at the previous moment to obtain the output at time <strong><i>t</i></strong> , as shown in equation (3-6):</p>",
    "p13": "<p>Where <strong><i>h<sub>t-1</sub></i></strong>is the hidden layer output at the current moment and the function <strong><i>g</i></strong> is the activation function, <strong><i>W<sub>h</sub></i></strong> is the weight that converts the output of the previous moment to the output of the current moment, <strong><i>W<sub>h</sub></i></strong>  is the weight that converts the input <strong><i>x</i></strong> to the output <strong><i>h</i></strong> , and <strong><i>b</i></strong> is the bias.</p>",
    "p14": "As shown in Figure 3-2, the RNN layer at each moment receives the input of that layer and the output of the previous RNN layer, and then calculates the output of the current moment accordingly. Thus, the RNN is a \"layer with memory\" that captures the sequence information of the text."
  },
  "Article4": {
    "heading-1": "Island King 游戏礼包推荐系统",
    "p1": "随着电子计算机和移动设备的普及，游戏已经进入到越来越多人的日常生活中。一款良好设计的游戏既能让人享受虚拟世界带来的满足与幸福感，也能为游戏开发商带来巨大的收益。联网游戏的商业化主要足靠增值服务，比如虚拟道具的出售。在这种情况下，个性化推荐系统慢慢成为游戏运营中不可或缺的一部分。一方面，玩家在游戏过程中可能需要更好的引导，适时地为玩家推荐道具能够改善用户体验；另一方面运营商也能够享受道具出售带来的收益，如此形成一个良性循环。",
    "p2": "传统的个性化推荐方法主要包括协同过滤和基于内容的推荐两种方法，其中协同过滤方法主要根据用户的浏览、购买行为进行推荐，常见的CF方法包括基于近邻的方法，矩阵分解方法，SVD++和FM等；而基于内容的推荐方法则对用户和商品的画像进行了建模，以便进行更好的推荐。然而，对于虛拟商品特別是游戏中道具这种虚拟商品，此类现有方法往往难以取得很好效果。",
    "p3": "游戏道具具有复杂上下文相关性。用户对游戏道具的兴趣不仅仅受到其他同类玩家的影响，更加受到游戏上下文，即剧情、难度的影响，甚至后者的影响更大。此类上下文表现极为复杂，可能是游戏中的场景、其他同类玩家或者玩家本身的一个举动，都可能触发用户对某种道具的暂时性购买需求，此时迅速而不频繁的给出推荐，一方面能够帮助用户克服困难、流畅游戏体验，另一方而也能同时带来收益转化。",
    "header-main-1": "主要任务",
    "p4": "我们需要推荐给用户的礼包，其中包含礼包的精力值、金币数、砖石数、宠物粮食数以及礼包金额，还有礼包的下次刷新时间。推荐算法的主要任务就是从可选礼包中选出玩家最可能购买的礼包，以最大化平均对每个用户推荐产生的收益。",
    "header-main-2": "算法简介",
    "header-sub-1": "cfwV1",
    "p5": "cfwV1是开发的第一个版本的协同过滤算法，主要有四个步骤，分别为用户分层、计算物品相似度、计算增加时间衰减后的最终得分和推荐策略。",
    "header-sub-2": "·用户分层：",
    "p6": "对用户按照’pay_amt’(用户特征：用户的总付费额)进行分类，将用户分为大、中、小三层，每层分别进行物品相似度的计算。",
    "header-sub-3": "· 物品相似度计算：",
    "p7": "对于不同层级的用户数据分别计算出不同的物品相似度矩阵，计算公式如下所示：",
    "p8": "其中N(i)表示购买过i礼包的用户集合，|N(i)|表示集合N(i)中的用户数量。",
    "header-sub-4": "· 计算用户u对礼包i的最终得分：",
    "p9": "① 若用户之前有过购买礼包的行为记录，则用物品相似度矩阵来计算用户对各个礼包的打分，计算公式如下：",
    "p10": "其中N(u)表示用户u购买过的礼包集合，t表示当前时间，tj表示用户购买j礼包时的时间(在cfwV1模型中，若tj与t的间隔时间为7天，则t-tj=1)，wji表示礼包j与礼包i的相似度。",
    "p11": "② 若用户之前没有买过礼包的记录，则采用冷启动的打分方案：用户u对礼包i的打分为用户u所在层级中所有用户第一次购买的礼包为礼包i的数量。",
    "header-sub-5": "· 推荐策略：",
    "p12": "有了用户u对礼包i的打分之后，还需要确定如何使用这些分数得到最后的推荐结果。cfwV1模型采用的是期望采样推荐，即给用户u推荐礼包i的概率为：",
    "header-main-3": "RFM",
    "p13": "RFM模型是衡量客户价值和客户创造利益能力的重要工具和手段。在众多的客户关系管理(CRM)的分析模式中，RFM模型是被广泛提到的。该机械模型通过一个客户的近期购买行为、购买的总体频率以及花了多少钱这三项指标来描述该客户的价值状况。在当前的应用中，R(Recent)表示用户上次购买礼包距今的天数，F(Frequency)表示用户前7天购买礼包的次数，M(Monetary)表示用户前7天购买礼包的金额。RFM模型即是根据这三个用户特征对用户进行分层，的对不同层次的用户推荐不同的礼包。",
    "header-main-4": "cfwV2以及两种推荐策略",
    "p14": "cfwV2只改变了最总得分的计算公式和推荐策略，cfwV2模型中只记录用户近两个月的购买数据，而cfwV1模型中记录了用户之前所有的购买数据；cfwV2模型中修改了时间间隔的单位(当t与tj的间隔为2天时，t-tj=1)。 Price Sample(PS)：与cfwV1中的推荐策略相同，即考虑了礼包的价格之后再进行采样。 User inducement(UI)：在PS采样完成的基础上，给用户推荐的礼包有25%的概率变为下一个等级的礼包。",
    "heading-2": "Island King 测试方案及指标",
    "p15": "对于不同的模型采用了A/B测试方案，本质上就是把平台的流量均匀地分为几个组，在每个组上使用不同的推荐模型/算法，然后根据这几个组的用户数据指标比较模型/算法的好坏。",
    "p16": "第一次测试主要测试了cfwV1(第一版协同过滤模型)与RFM模型的各个指标；第二次测试主要测试了同一个模型cfwV2在不同推荐策略(加入用户诱导(user inducement, UI)，不加入用户诱导(price sample, PS))下的各个指标的对比。",
    "p17": "该模型成功地诱导了用户去购买原本高于他应购买的礼包。总结来说，采用用户诱导的策略在刚开始的时候可能会受到用户的抵触，但之后会潜移默化地改变用户的购买行为，达到测试的目标。"
  }
}
